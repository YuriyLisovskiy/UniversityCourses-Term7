{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "from lib.learn_problem import Learner, error_example\n",
    "from lib.learn_no_inputs import point_prediction, target_counts, selections\n",
    "\n",
    "\n",
    "class DT_learner(Learner):\n",
    "\n",
    "    def __init__(self,\n",
    "        dataset,\n",
    "        to_optimize='sum-of-squares',\n",
    "        leaf_selection='mean',   # what to use for point prediction at leaves\n",
    "        train=None,              # used for cross validation\n",
    "        min_number_examples=10\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.target = dataset.target\n",
    "        self.to_optimize = to_optimize\n",
    "        self.leaf_selection = leaf_selection\n",
    "        self.min_number_examples = min_number_examples\n",
    "        if train is None:\n",
    "            self.train = self.dataset.train\n",
    "        else:\n",
    "            self.train = train\n",
    "\n",
    "    def learn(self):\n",
    "        return self.learn_tree(self.dataset.input_features, self.train)\n",
    "        \n",
    "    def learn_tree(self, input_features, data_subset):\n",
    "        \"\"\"returns a decision tree\n",
    "        for input_features is a set of possible conditions\n",
    "        data_subset is a subset of the data used to build this (sub)tree\n",
    "\n",
    "        where a decision tree is a function that takes an example and\n",
    "        makes a prediction on the target feature\n",
    "        \"\"\"\n",
    "        if (input_features and len(data_subset) >= self.min_number_examples):\n",
    "            first_target_val = self.target(data_subset[0])\n",
    "            allagree = all(self.target(inst) == first_target_val for inst in data_subset)\n",
    "            if not allagree:\n",
    "                split, partn = self.select_split(input_features, data_subset)\n",
    "                if split: # the split succeeded in splitting the data\n",
    "                    false_examples, true_examples = partn\n",
    "                    rem_features = [fe for fe in input_features if fe != split]\n",
    "                    self.display(\n",
    "                        2, 'Splitting on', split.__doc__, 'with examples split',\n",
    "                        len(true_examples), ':', len(false_examples)\n",
    "                    )\n",
    "                    true_tree = self.learn_tree(rem_features, true_examples)\n",
    "                    false_tree =  self.learn_tree(rem_features, false_examples)\n",
    "                    def fun(e):\n",
    "                        if split(e):\n",
    "                            return true_tree(e)\n",
    "                        else:\n",
    "                            return false_tree(e)\n",
    "                    #fun = lambda e: true_tree(e) if split(e) else false_tree(e)\n",
    "                    fun.__doc__ = (\n",
    "                        'if ' + split.__doc__ + ' then (' + true_tree.__doc__ +\n",
    "                        ') else (' + false_tree.__doc__ + ')'\n",
    "                    )\n",
    "                    return fun\n",
    "        # don't expand the trees but return a point prediction\n",
    "        return point_prediction(self.target, data_subset, selection=self.leaf_selection)\n",
    "        \n",
    "    def select_split(self, input_features, data_subset):\n",
    "        \"\"\"finds best feature to split on.\n",
    "\n",
    "        input_features is a non-empty list of features.\n",
    "        returns feature, partition\n",
    "        where feature is an input feature with the smallest error as\n",
    "              judged by to_optimize or\n",
    "              feature==None if there are no splits that improve the error\n",
    "        partition is a pair (false_examples, true_examples) if feature is not None\n",
    "        \"\"\"\n",
    "        best_feat = None # best feature\n",
    "        # best_error = float(\"inf\")  # infinity - more than any error\n",
    "        best_error = training_error(self.dataset, data_subset, self.to_optimize)\n",
    "        best_partition = None\n",
    "        for feat in input_features:\n",
    "            false_examples, true_examples = partition(data_subset, feat)\n",
    "            if false_examples and true_examples:  #both partitons are non-empty\n",
    "                err = (\n",
    "                    training_error(self.dataset, false_examples, self.to_optimize)\n",
    "                    +\n",
    "                    training_error(self.dataset, true_examples, self.to_optimize)\n",
    "                )\n",
    "                self.display(\n",
    "                    3, '   split on', feat.__doc__, 'has err=', err,\n",
    "                    'splits into', len(true_examples), ':', len(false_examples)\n",
    "                )\n",
    "                if err < best_error:\n",
    "                    best_feat = feat\n",
    "                    best_error = err\n",
    "                    best_partition = false_examples, true_examples\n",
    "        self.display(3, 'best split is on', best_feat.__doc__, 'with err=', best_error)\n",
    "        return best_feat, best_partition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(data_subset, feature):\n",
    "    \"\"\"partitions the data_subset by the feature\"\"\"\n",
    "    true_examples = []\n",
    "    false_examples = []\n",
    "    for example in data_subset:\n",
    "        if feature(example):\n",
    "            true_examples.append(example)\n",
    "        else:\n",
    "            false_examples.append(example)\n",
    "    return false_examples, true_examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_error(dataset, data_subset, to_optimize):\n",
    "    \"\"\"returns training error for dataset on to_optimize.\n",
    "    This assumes that we choose the best value for the optimization\n",
    "    criteria for dataset according to point_prediction\n",
    "    \"\"\"\n",
    "    select_dict = {\n",
    "        'sum-of-squares': 'mean',\n",
    "        'sum_absolute': 'median',\n",
    "        'logloss': 'Laplace'\n",
    "    }  # arbitrary mapping. Perhaps wrong.\n",
    "    selection = select_dict[to_optimize]\n",
    "    predictor = point_prediction(dataset.target, data_subset, selection=selection)\n",
    "    error = sum(\n",
    "        error_example(predictor(example), dataset.target(example), to_optimize) for example in data_subset\n",
    "    )\n",
    "    return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.learn_problem import Data_set, Data_from_file\n",
    "\n",
    "def test(data):\n",
    "    \"\"\"Prints errors and the trees for various evaluation criteria and ways to select leaves.\n",
    "    \"\"\"\n",
    "    for crit in Data_set.evaluation_criteria:\n",
    "        for leaf in selections:\n",
    "            tree = DT_learner(data, to_optimize=crit, leaf_selection=leaf).learn()\n",
    "            print('For', crit, 'using', leaf, 'at leaves, tree built is:', tree.__doc__)\n",
    "            if data.test:\n",
    "                for ecrit in Data_set.evaluation_criteria:\n",
    "                    test_error = data.evaluate_dataset(data.test, tree, ecrit)\n",
    "                    print('    Average error for', ecrit, 'using', leaf, 'at leaves is', test_error)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mail_reading.csv\n",
      "Tuples read. \n",
      "Training set 24 examples. Number of columns: {5} \n",
      "Test set 4 examples. Number of columns: {5}\n",
      "There are 4 input features\n",
      "   split on e[0]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 5.583333333333334 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 2.769230769230769 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 2.769230769230769\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 2.5476190476190474 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 2.761904761904762 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 2.6750000000000003 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 2.5476190476190474\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For sum-of-squares using median at leaves, tree built is: if e[2]==1 then (1) else (if e[0]==1 then (0) else (0))\n",
      "    Average error for sum-of-squares using median at leaves is 0.0\n",
      "    Average error for sum_absolute using median at leaves is 0.0\n",
      "    Average error for logloss using median at leaves is 0.0\n",
      "   split on e[0]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 5.583333333333334 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 2.769230769230769 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 2.769230769230769\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 2.5476190476190474 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 2.761904761904762 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 2.6750000000000003 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 2.5476190476190474\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For sum-of-squares using mean at leaves, tree built is: if e[2]==1 then (1.0) else (if e[0]==1 then (0.16666666666666666) else (0.42857142857142855))\n",
      "    Average error for sum-of-squares using mean at leaves is 0.020833333333333332\n",
      "    Average error for sum_absolute using mean at leaves is 0.125\n",
      "    Average error for logloss using mean at leaves is 0.19727580437534534\n",
      "   split on e[0]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 5.583333333333334 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 2.769230769230769 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 5.622377622377623 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 2.769230769230769\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 2.5476190476190474 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 2.761904761904762 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 2.6750000000000003 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 2.5476190476190474\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For sum-of-squares using Laplace at leaves, tree built is: if e[2]==1 then (0.9230769230769231) else (if e[0]==1 then (0.25) else (0.4444444444444444))\n",
      "    Average error for sum-of-squares using Laplace at leaves is 0.0483542899408284\n",
      "    Average error for sum_absolute using Laplace at leaves is 0.20673076923076922\n",
      "    Average error for logloss using Laplace at leaves is 0.34014742881411686\n",
      "   split on e[0]==1 has err= 9 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 9 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 4 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 9 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 4\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 4 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 4 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 4 splits into 8 : 5\n",
      "best split is on None with err= 4\n",
      "For sum_absolute using median at leaves, tree built is: if e[2]==1 then (1) else (0)\n",
      "    Average error for sum-of-squares using median at leaves is 0.0\n",
      "    Average error for sum_absolute using median at leaves is 0.0\n",
      "    Average error for logloss using median at leaves is 0.0\n",
      "   split on e[0]==1 has err= 9 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 9 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 4 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 9 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 4\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 4 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 4 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 4 splits into 8 : 5\n",
      "best split is on None with err= 4\n",
      "For sum_absolute using mean at leaves, tree built is: if e[2]==1 then (1.0) else (0.3076923076923077)\n",
      "    Average error for sum-of-squares using mean at leaves is 0.07100591715976332\n",
      "    Average error for sum_absolute using mean at leaves is 0.23076923076923078\n",
      "    Average error for logloss using mean at leaves is 0.39788603752408486\n",
      "   split on e[0]==1 has err= 9 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 9 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 4 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 9 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 4\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 4 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 4 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 4 splits into 8 : 5\n",
      "best split is on None with err= 4\n",
      "For sum_absolute using Laplace at leaves, tree built is: if e[2]==1 then (0.9230769230769231) else (0.3333333333333333)\n",
      "    Average error for sum-of-squares using Laplace at leaves is 0.08481262327416172\n",
      "    Average error for sum_absolute using Laplace at leaves is 0.2692307692307692\n",
      "    Average error for logloss using Laplace at leaves is 0.46759117989585103\n",
      "   split on e[0]==1 has err= 22.922489747769028 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 22.804593234688767 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 12.874761900994324 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 22.92248974776902 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 12.874761900994324\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 10.976950126940958 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 11.63710012405633 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 11.399674486231687 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 10.976950126940958\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For logloss using median at leaves, tree built is: if e[2]==1 then (1) else (if e[0]==1 then (0) else (0))\n",
      "    Average error for sum-of-squares using median at leaves is 0.0\n",
      "    Average error for sum_absolute using median at leaves is 0.0\n",
      "    Average error for logloss using median at leaves is 0.0\n",
      "   split on e[0]==1 has err= 22.922489747769028 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 22.804593234688767 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 12.874761900994324 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 22.92248974776902 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 12.874761900994324\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 10.976950126940958 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 11.63710012405633 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 11.399674486231687 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 10.976950126940958\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For logloss using mean at leaves, tree built is: if e[2]==1 then (1.0) else (if e[0]==1 then (0.16666666666666666) else (0.42857142857142855))\n",
      "    Average error for sum-of-squares using mean at leaves is 0.020833333333333332\n",
      "    Average error for sum_absolute using mean at leaves is 0.125\n",
      "    Average error for logloss using mean at leaves is 0.19727580437534534\n",
      "   split on e[0]==1 has err= 22.922489747769028 splits into 13 : 11\n",
      "   split on e[1]==1 has err= 22.804593234688767 splits into 12 : 12\n",
      "   split on e[2]==1 has err= 12.874761900994324 splits into 11 : 13\n",
      "   split on e[3]==1 has err= 22.92248974776902 splits into 13 : 11\n",
      "best split is on e[2]==1 with err= 12.874761900994324\n",
      "Splitting on e[2]==1 with examples split 11 : 13\n",
      "   split on e[0]==1 has err= 10.976950126940958 splits into 6 : 7\n",
      "   split on e[1]==1 has err= 11.63710012405633 splits into 7 : 6\n",
      "   split on e[3]==1 has err= 11.399674486231687 splits into 8 : 5\n",
      "best split is on e[0]==1 with err= 10.976950126940958\n",
      "Splitting on e[0]==1 with examples split 6 : 7\n",
      "For logloss using Laplace at leaves, tree built is: if e[2]==1 then (0.9230769230769231) else (if e[0]==1 then (0.25) else (0.4444444444444444))\n",
      "    Average error for sum-of-squares using Laplace at leaves is 0.0483542899408284\n",
      "    Average error for sum_absolute using Laplace at leaves is 0.20673076923076922\n",
      "    Average error for logloss using Laplace at leaves is 0.34014742881411686\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #print(\"carbool.csv\"); test(data = Data_from_file('data/carbool.csv', target_index=-1))\n",
    "    # print(\"SPECT.csv\"); test(data = Data_from_file('data/SPECT.csv', target_index=0))\n",
    "    print(\"mail_reading.csv\"); test(data = Data_from_file('data/mail_reading.csv', target_index=-1))\n",
    "    # print(\"holiday.csv\"); test(data = Data_from_file('data/holiday.csv', num_train=19, target_index=-1))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
