{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import math, random\n",
    "from lib.display import Displayable\n",
    "\n",
    "boolean = [False, True]\n",
    "\n",
    "\n",
    "class Data_set(Displayable):\n",
    "    \"\"\" A data set consists of a list of training data and a list of test data.\n",
    "    \"\"\"\n",
    "    \n",
    "    seed = None #123456  # make it None for a different test set each time\n",
    "\n",
    "    def __init__(self, train, test=None, prob_test=0.30, target_index=0, header=None):\n",
    "        \"\"\"A dataset for learning.\n",
    "        train is a list of tuples representing the training examples\n",
    "        test is the list of tuples representing the test examples\n",
    "        if test is None, a test set is created by selecting each\n",
    "            example with probability prob_test\n",
    "        target_index is the index of the target. If negative, it counts from right.\n",
    "            If target_index is larger than the number of properties,\n",
    "            there is no target (for unsupervised learning)\n",
    "        header is a list of names for the features\n",
    "        \"\"\"\n",
    "        if test is None:\n",
    "            train,test = partition_data(train, prob_test, seed=self.seed)\n",
    "        self.train = train\n",
    "        self.test = test\n",
    "        self.display(1,\"Tuples read. \\nTraining set\", len(train),\n",
    "                    \"examples. Number of columns:\",{len(e) for e in train},\n",
    "                    \"\\nTest set\", len(test),\n",
    "                    \"examples. Number of columns:\",{len(e) for e in test}\n",
    "                    )\n",
    "        self.prob_test = prob_test\n",
    "        self.num_properties = len(self.train[0])\n",
    "        if target_index < 0:   #allows for -1, -2, etc.\n",
    "            target_index = self.num_properties + target_index\n",
    "        self.target_index = target_index\n",
    "        self.header = header\n",
    "        self.create_features()\n",
    "        self.display(1, \"There are\", len(self.input_features), \"input features\")\n",
    "\n",
    "    def create_features(self):\n",
    "        \"\"\"create the input features and target feature.\n",
    "        This assumes that the features all have range {0,1}.\n",
    "        This should be overridden if the features have a different range.\n",
    "        \"\"\"\n",
    "        self.input_features = []\n",
    "        for i in range(self.num_properties):\n",
    "            def feat(e, index=i):\n",
    "                return e[index]\n",
    "            if self.header:\n",
    "                feat.__doc__ = self.header[i]\n",
    "            else:\n",
    "                feat.__doc__ = \"e[\" + str(i) + \"]\"\n",
    "            feat.frange = [0, 1]\n",
    "            if i == self.target_index:\n",
    "                self.target = feat\n",
    "            else:\n",
    "                self.input_features.append(feat)\n",
    "\n",
    "    evaluation_criteria = [\"sum-of-squares\", \"sum_absolute\", \"logloss\"]\n",
    "        \n",
    "    def evaluate_dataset(self, data, predictor, evaluation_criterion):\n",
    "        \"\"\"Evaluates predictor on data according to the evaluation_criterion.\n",
    "        predictor is a function that takes an example and returns a\n",
    "                prediction for the target feature. \n",
    "        evaluation_criterion is one of the  evaluation_criteria.\n",
    "        \"\"\"\n",
    "        assert evaluation_criterion in self.evaluation_criteria, \"given: \" + str(evaluation_criterion)\n",
    "        if data:\n",
    "            try:\n",
    "                error = sum(error_example(\n",
    "                        predictor(example),\n",
    "                        self.target(example),\n",
    "                        evaluation_criterion\n",
    "                    ) for example in data\n",
    "                ) / len(data)\n",
    "            except ValueError:\n",
    "                return float(\"inf\")  # infinity \n",
    "            return error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_example(predicted, actual, evaluation_criterion):\n",
    "    \"\"\"returns the error of the for the predicted value given the actual value \n",
    "    according to evaluation_criterion.\n",
    "    Throws ValueError if the error is infinite (log(0))\n",
    "    \"\"\"\n",
    "    if evaluation_criterion == \"sum-of-squares\":\n",
    "        return (predicted - actual) ** 2\n",
    "    elif evaluation_criterion == \"sum_absolute\":\n",
    "        return abs(predicted - actual)\n",
    "    elif evaluation_criterion == \"logloss\":\n",
    "        assert actual in [0,1], \"actual=\" + str(actual)\n",
    "        if actual == 0:\n",
    "            return -math.log2(1 - predicted)\n",
    "        else:\n",
    "            return -math.log2(predicted)\n",
    "    elif evaluation_criterion == \"characteristic_ss\":\n",
    "        return sum((1 - predicted[i]) ** 2 if actual == i else predicted[i] ** 2\n",
    "                       for i in range(len(predicted)))\n",
    "    else:\n",
    "        raise RuntimeError(\"Not evaluation criteria: \" + str(evaluation_criterion))\n",
    "\n",
    "\n",
    "def partition_data(data, prob_test=0.30, seed=None):\n",
    "    \"\"\"partitions the data into a training set and a test set, where\n",
    "    prob_test is the probability of each example being in the test set.\n",
    "    \"\"\"\n",
    "    train = []\n",
    "    test = []\n",
    "    if seed:     # given seed makes the partition consistent from run-to-run\n",
    "        random.seed(seed)\n",
    "    for example in data:\n",
    "        if random.random() < prob_test:\n",
    "            test.append(example)\n",
    "        else:\n",
    "            train.append(example)\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_from_file(Data_set):\n",
    "    \n",
    "    def __init__(self, file_name, separator=',', num_train=None, prob_test=0.3,\n",
    "                 has_header=False, target_index=0, boolean_features=True,\n",
    "                 categorical=[], include_only=None):\n",
    "        \"\"\"create a dataset from a file\n",
    "        separator is the character that separates the attributes\n",
    "        num_train is a number n specifying the first n tuples are training, or None \n",
    "        prob_test is the probability an example should in the test set (if num_train is None)\n",
    "        has_header is True if the first line of file is a header\n",
    "        target_index specifies which feature is the target\n",
    "        boolean_features specifies whether we want to create Boolean features\n",
    "            (if False, is uses the original features).\n",
    "        categorical is a set (or list) of features that should be treated as categorical\n",
    "        include_only is a list or set of indexes of columns to include\n",
    "        \"\"\"\n",
    "        self.boolean_features = boolean_features\n",
    "        with open(file_name, 'r', newline='') as csvfile:\n",
    "            # data_all = csv.reader(csvfile,delimiter=separator)  # for more complicted CSV files\n",
    "            data_all = (line.strip().split(separator) for line in csvfile)\n",
    "            if include_only is not None:\n",
    "                data_all = ([v for (i, v) in enumerate(line) if i in include_only] for line in data_all)\n",
    "            if has_header:\n",
    "                header = next(data_all)\n",
    "            else:\n",
    "                header = None\n",
    "            data_tuples = (make_num(d) for d in data_all if len(d) > 1)\n",
    "            if num_train is not None:\n",
    "                # training set is divided into training then text examples\n",
    "                # the file is only read once, and the data is placed in appropriate list\n",
    "                train = []\n",
    "                for i in range(num_train):     # will give an error if insufficient examples\n",
    "                    train.append(next(data_tuples))\n",
    "                test = list(data_tuples)\n",
    "                Data_set.__init__(self, train, test=test, target_index=target_index, header=header)\n",
    "            else:     # randomly assign training and test examples\n",
    "                Data_set.__init__(self, data_tuples, prob_test=prob_test, target_index=target_index, header=header)\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.train and len(self.train) > 0: \n",
    "            return (\"Data: \" + str(len(self.train)) + \" training examples, \"\n",
    "                    + str(len(self.test)) + \" test examples, \"\n",
    "                    + str(len(self.train[0])) + \" features.\")\n",
    "        else:\n",
    "            return (\"Data: \" + str(len(self.train)) + \" training examples, \"\n",
    "                    + str(len(self.test)) + \" test examples.\")\n",
    "\n",
    "    def create_features(self, max_num_cuts=8):\n",
    "        \"\"\"creates boolean features from input features.\n",
    "        max_num_cuts is the maximum number of binary variables\n",
    "           to split a numerical feature into. \n",
    "        \"\"\"\n",
    "        ranges = [set() for i in range(self.num_properties)]\n",
    "        for example in self.train:\n",
    "            for ind, val in enumerate(example):\n",
    "                ranges[ind].add(val)\n",
    "        if self.target_index <= self.num_properties:\n",
    "            def target(e, index=self.target_index):\n",
    "                return e[index]\n",
    "            if self.header:\n",
    "                target.__doc__ = self.header[ind]\n",
    "            else:\n",
    "                target.__doc__ = \"e[\" + str(ind) + \"]\"\n",
    "            target.frange = ranges[self.target_index]\n",
    "            self.target = target\n",
    "        if self.boolean_features:\n",
    "            self.input_features = []\n",
    "            for ind,frange in enumerate(ranges):\n",
    "                if ind != self.target_index and len(frange) > 1:\n",
    "                    if len(frange) == 2:\n",
    "                        # two values, the feature is equality to one of them.\n",
    "                        true_val = list(frange)[1] # choose one as true\n",
    "                        def feat(e, i=ind, tv=true_val):\n",
    "                            return e[i] == tv\n",
    "                        if self.header:\n",
    "                            feat.__doc__ = self.header[ind] + \"==\" + str(true_val)\n",
    "                        else:\n",
    "                            feat.__doc__ = \"e[\" + str(ind) + \"]==\" + str(true_val)\n",
    "                        feat.frange = boolean\n",
    "                        self.input_features.append(feat)\n",
    "                    elif all(isinstance(val, (int, float)) for val in frange):\n",
    "                        # all numeric, create cuts of the data\n",
    "                        sorted_frange = sorted(frange)\n",
    "                        num_cuts = min(max_num_cuts, len(frange))\n",
    "                        cut_positions = [len(frange) * i // num_cuts for i in range(1, num_cuts)]\n",
    "                        for cut in cut_positions:\n",
    "                            cutat = sorted_frange[cut]\n",
    "                            def feat(e, ind_=ind, cutat=cutat):\n",
    "                                return e[ind_] < cutat\n",
    "                            \n",
    "                            if self.header:\n",
    "                                feat.__doc__ = self.header[ind] + \"<\" + str(cutat)\n",
    "                            else:\n",
    "                                feat.__doc__ = \"e[\" + str(ind) + \"]<\" + str(cutat)\n",
    "                            feat.frange = boolean\n",
    "                            self.input_features.append(feat)\n",
    "                    else:\n",
    "                        # create an indicator function for every value\n",
    "                        for val in frange:\n",
    "                            def feat(e, ind_=ind, val_=val):\n",
    "                                return e[ind_] == val_\n",
    "                            if self.header:\n",
    "                                feat.__doc__ = self.header[ind] + \"==\" + str(val)\n",
    "                            else:\n",
    "                                feat.__doc__= \"e[\" + str(ind) + \"]==\" + str(val)\n",
    "                            feat.frange = boolean\n",
    "                            self.input_features.append(feat)\n",
    "        else: # boolean_features is off\n",
    "            self.input_features = []\n",
    "            for i in range(self.num_properties):\n",
    "                def feat(e, index=i):\n",
    "                    return e[index]\n",
    "                if self.header:\n",
    "                    feat.__doc__ = self.header[i]\n",
    "                else:\n",
    "                     feat.__doc__ = \"e[\" + str(i) + \"]\"\n",
    "                feat.frange = ranges[i]\n",
    "                if i == self.target_index:\n",
    "                    self.target = feat\n",
    "                else:\n",
    "                    self.input_features.append(feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_num(str_list):\n",
    "    \"\"\"make the elements of string list str_list numerical if possible.\n",
    "    Otherwise remove initial and trailing spaces.\n",
    "    \"\"\"\n",
    "    res = []\n",
    "    for e in str_list:\n",
    "        try:\n",
    "            res.append(int(e))\n",
    "        except ValueError:\n",
    "            try:\n",
    "                res.append(float(e))\n",
    "            except ValueError:\n",
    "                res.append(e.strip())\n",
    "    return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_set_augmented(Data_set):\n",
    "    \n",
    "    def __init__(self, dataset, unary_functions=[], binary_functions=[], include_orig=True):\n",
    "        \"\"\"creates a dataset like dataset but with new features\n",
    "        unary_function is a list of  unary feature constructors\n",
    "        binary_functions is a list of  binary feature combiners.\n",
    "        include_orig specifies whether the original features should be included\n",
    "        \"\"\"\n",
    "        self.orig_dataset = dataset\n",
    "        self.unary_functions = unary_functions\n",
    "        self.binary_functions = binary_functions\n",
    "        self.include_orig = include_orig\n",
    "        self.target = dataset.target\n",
    "        Data_set.__init__(self, dataset.train, test=dataset.test, target_index=dataset.target_index)\n",
    "\n",
    "    def create_features(self):\n",
    "        if self.include_orig:\n",
    "            self.input_features = self.orig_dataset.input_features.copy()\n",
    "        else:\n",
    "            self.input_features = []\n",
    "        for u in self.unary_functions:\n",
    "            for f in self.orig_dataset.input_features:\n",
    "                self.input_features.append(u(f))\n",
    "        for b in self.binary_functions:\n",
    "            for f1 in self.orig_dataset.input_features:\n",
    "                for f2 in self.orig_dataset.input_features:\n",
    "                    if f1 != f2:\n",
    "                        self.input_features.append(b(f1, f2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def square(f):\n",
    "    \"\"\"a unary  feature constructor to construct the square of a feature\n",
    "    \"\"\"\n",
    "    def sq(e):\n",
    "        return f(e) ** 2\n",
    "    sq.__doc__ = f.__doc__ + \"**2\"\n",
    "    return sq\n",
    "\n",
    "\n",
    "def power_feat(n):\n",
    "    \"\"\"given n returns a unary  feature constructor to construct the nth power of a feature.\n",
    "    e.g., power_feat(2) is the same as square\n",
    "    \"\"\"\n",
    "    def fn(f, n=n):\n",
    "        def pow(e, n=n):\n",
    "            return f(e) ** n\n",
    "        pow.__doc__ = f.__doc__ + \"**\" + str(n)\n",
    "        return pow\n",
    "    return fn\n",
    "\n",
    "\n",
    "def prod_feat(f1, f2):\n",
    "    \"\"\"a new feature that is the product of features f1 and f2\n",
    "    \"\"\"\n",
    "    def feat(e):\n",
    "        return f1(e) * f2(e)\n",
    "    feat.__doc__ = f1.__doc__ + \"*\" + f2.__doc__\n",
    "    return feat\n",
    "\n",
    "\n",
    "def eq_feat(f1, f2):\n",
    "    \"\"\"a new feature that is 1 if f1 and f2 give same value\n",
    "    \"\"\"\n",
    "    def feat(e):\n",
    "        return 1 if f1(e) == f2(e) else 0\n",
    "    feat.__doc__ = f1.__doc__ + \"==\" + f2.__doc__\n",
    "    return feat\n",
    "\n",
    "\n",
    "def neq_feat(f1, f2):\n",
    "    \"\"\"a new feature that is 1 if f1 and f2 give different values\n",
    "    \"\"\"\n",
    "    def feat(e):\n",
    "        return 1 if f1(e) != f2(e) else 0\n",
    "    feat.__doc__ = f1.__doc__ + \"!=\" + f2.__doc__\n",
    "    return feat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lib.display import Displayable\n",
    "\n",
    "\n",
    "class Learner(Displayable):\n",
    "    \n",
    "    def __init__(self, dataset):\n",
    "        raise NotImplementedError(\"Learner.__init__\")    # abstract method\n",
    "\n",
    "    def learn(self):\n",
    "        \"\"\"returns a predictor, a function from a tuple to a value for the target feature\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"learn\")    # abstract method\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuples read. \n",
      "Training set 142 examples. Number of columns: {23} \n",
      "Test set 125 examples. Number of columns: {23}\n",
      "There are 22 input features\n",
      "Tuples read. \n",
      "Training set 142 examples. Number of columns: {23} \n",
      "Test set 125 examples. Number of columns: {23}\n",
      "There are 946 input features\n",
      "<__main__.Data_set_augmented object at 0x7f4800116c50>\n"
     ]
    }
   ],
   "source": [
    "# data = Data_from_file('data/holiday.csv', num_train=19, target_index=-1)\n",
    "data = Data_from_file('data/SPECT.csv',  prob_test=0.5, target_index=0)\n",
    "# dataplus = Data_set_augmented(data, [], [prod_feat])\n",
    "dataplus = Data_set_augmented(data, [], [prod_feat, neq_feat])\n",
    "\n",
    "print(dataplus)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
