{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, random\n",
    "from lib.learn_problem import Learner, Data_set\n",
    "\n",
    "selections = ['median', 'mean', 'Laplace']\n",
    "\n",
    "\n",
    "def point_prediction(target, training_data, selection='mean'):\n",
    "    \"\"\"makes a point prediction for a set of training data.\n",
    "    target provides the target\n",
    "    training_data provides the training data to use (often a subset of train).\n",
    "    selection specifies what statistic of the data to use as the evaluation.\n",
    "    to_optimize provides a criteria to optimize (used to guess selection)\n",
    "    \"\"\"\n",
    "    assert len(training_data) > 0\n",
    "    if selection == 'median':\n",
    "        counts, total = target_counts(target, training_data)\n",
    "        middle = total / 2\n",
    "        cumulative = 0\n",
    "        for val, num in sorted(counts.items()):\n",
    "            cumulative += num\n",
    "            if cumulative > middle:\n",
    "                break  # exit loop with val as the median\n",
    "    elif selection == 'mean':\n",
    "        val = mean((target(e) for e in training_data))\n",
    "    elif selection == 'Laplace':\n",
    "        val = mean((target(e) for e in training_data), len(target.frange), 1)\n",
    "    elif selection == 'mode':\n",
    "        raise NotImplementedError('mode')\n",
    "    else:\n",
    "        raise RuntimeError('Not valid selection: {}'.format(selection))\n",
    "    fun = lambda x: val\n",
    "    fun.__doc__ = str(val)\n",
    "    return fun\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean(enum, count=0, sum_=0):\n",
    "    \"\"\"returns the mean of enumeration enum, \n",
    "       count and sum are initial counts and the initial sum.\n",
    "       This works for enumerations, even where len() is not defined\"\"\"\n",
    "    for e in enum:\n",
    "        count += 1\n",
    "        sum_ += e\n",
    "    return sum_ / count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_counts(target, data_subset):\n",
    "    \"\"\"returns a value:count dictionary of the count of the number of\n",
    "    times target has this value in data_subset, and the number of examples.\n",
    "    \"\"\"\n",
    "    counts = {val: 0 for val in target.frange}\n",
    "    total = 0\n",
    "    for instance in data_subset:\n",
    "        total += 1\n",
    "        counts[target(instance)] += 1\n",
    "    return counts, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Data_set_random(Data_set):\n",
    "    \"\"\"A data set of a {0,1} feature generated randomly given a probability\"\"\"\n",
    "    \n",
    "    def __init__(self, prob, train_size, test_size=100):\n",
    "        \"\"\"a data set of with train_size training examples,\n",
    "        test_size test examples\n",
    "        where each examples in generated where prob i the probability of 1\n",
    "        \"\"\"\n",
    "        self.max_display_level = 0\n",
    "        train = [[1] if random.random() < prob else [0] for i in range(train_size)]\n",
    "        test =  [[1] if random.random() < prob else [0] for i in range(test_size)]\n",
    "        Data_set.__init__(self, train, test, target_index=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_no_inputs():\n",
    "    num_samples = 1000  # number of runs to average over\n",
    "    test_size = 100     # number of test examples for each prediction\n",
    "    for train_size in [1, 2, 3, 4, 5, 10, 20, 100, 1000]:\n",
    "        total_error = {(select, crit): 0\n",
    "                          for select in selections\n",
    "                          for crit in Data_set.evaluation_criteria\n",
    "                      }\n",
    "        for sample in range(num_samples):   # average over num_samples\n",
    "            p = random.random()\n",
    "            data = Data_set_random(p, train_size, test_size)\n",
    "            for select in selections:\n",
    "                prediction = point_prediction(data.target, data.train, selection=select)\n",
    "                for ecrit in Data_set.evaluation_criteria:\n",
    "                    test_error = data.evaluate_dataset(data.test, prediction, ecrit)\n",
    "                    total_error[(select, ecrit)] += test_error\n",
    "        print('For training size', train_size, ':')\n",
    "        for ecrit in Data_set.evaluation_criteria:\n",
    "            print('    Evaluated according to', ecrit, ':')\n",
    "            for select in selections:\n",
    "                print('        Average error of', select, 'is', total_error[(select, ecrit)] / num_samples)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training size 1 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.34034999999999993\n",
      "        Average error of mean is 0.34034999999999993\n",
      "        Average error of Laplace is 0.22456111111111088\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.34034999999999993\n",
      "        Average error of mean is 0.34034999999999993\n",
      "        Average error of Laplace is 0.446783333333333\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.925312500721157\n",
      "For training size 2 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.3262000000000002\n",
      "        Average error of mean is 0.24770000000000014\n",
      "        Average error of Laplace is 0.20659999999999987\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.3262000000000002\n",
      "        Average error of mean is 0.3287000000000001\n",
      "        Average error of Laplace is 0.4143499999999999\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.8687785983827155\n",
      "For training size 3 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.30989000000000017\n",
      "        Average error of mean is 0.2247455555555556\n",
      "        Average error of Laplace is 0.20311399999999918\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.30989000000000017\n",
      "        Average error of mean is 0.3425233333333339\n",
      "        Average error of Laplace is 0.4055139999999994\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.8559591177859565\n",
      "For training size 4 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.2842199999999999\n",
      "        Average error of mean is 0.2022574999999999\n",
      "        Average error of Laplace is 0.18965777777777762\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.2842199999999999\n",
      "        Average error of mean is 0.3239449999999996\n",
      "        Average error of Laplace is 0.38263000000000036\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.8117930317383171\n",
      "For training size 5 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.28540999999999994\n",
      "        Average error of mean is 0.19843799999999967\n",
      "        Average error of Laplace is 0.1899863265306119\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.28540999999999994\n",
      "        Average error of mean is 0.3348379999999996\n",
      "        Average error of Laplace is 0.3820271428571437\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.8114925743156173\n",
      "For training size 10 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.2741999999999998\n",
      "        Average error of mean is 0.18343599999999965\n",
      "        Average error of Laplace is 0.1808369444444447\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.2741999999999998\n",
      "        Average error of mean is 0.3348459999999998\n",
      "        Average error of Laplace is 0.3623716666666665\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.7774208376330286\n",
      "For training size 20 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.2609200000000003\n",
      "        Average error of mean is 0.1756334999999998\n",
      "        Average error of Laplace is 0.1750079338842975\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.2609200000000003\n",
      "        Average error of mean is 0.33626100000000037\n",
      "        Average error of Laplace is 0.35114636363636337\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.7560630183410324\n",
      "For training size 100 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.2540700000000001\n",
      "        Average error of mean is 0.1685705000000001\n",
      "        Average error of Laplace is 0.16856768550557485\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.2540700000000001\n",
      "        Average error of mean is 0.33536600000000055\n",
      "        Average error of Laplace is 0.338594117647059\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is inf\n",
      "        Average error of Laplace is 0.728463107754015\n",
      "For training size 1000 :\n",
      "    Evaluated according to sum-of-squares :\n",
      "        Average error of median is 0.24508999999999978\n",
      "        Average error of mean is 0.1626547359999998\n",
      "        Average error of Laplace is 0.1626561075055479\n",
      "    Evaluated according to sum_absolute :\n",
      "        Average error of median is 0.24508999999999978\n",
      "        Average error of mean is 0.3258232800000005\n",
      "        Average error of Laplace is 0.326170938123752\n",
      "    Evaluated according to logloss :\n",
      "        Average error of median is inf\n",
      "        Average error of mean is 0.7066202593424311\n",
      "        Average error of Laplace is 0.7065954182726433\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    test_no_inputs()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
